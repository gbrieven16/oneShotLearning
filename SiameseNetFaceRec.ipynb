{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLOBAL VARIABLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "FILE = \"Aberdeen\"#.zip\"\n",
    "EXTENSION = \".jpg\"\n",
    "PATH = os.path.join(os.getcwd(),\"datasets\", FILE)\n",
    "BATCH_SIZE = 16\n",
    "DO_LEARN = False\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCH = 10 \n",
    "WEIGHT_DECAY = 0.0001\n",
    "SAVE_MODEL = True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANAGEMENT OF THE DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "from string import digits\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import random \n",
    "\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "STILL TODO: \n",
    "    - Better management of the dataset (during the composition of triplets)\n",
    "    - Build a Training and a Testing sets\n",
    "\"\"\"\n",
    "class Face_DS(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, root=PATH, train=False, transform=None):\n",
    "        \n",
    "        print(\"A Face Dataset is building ... \")\n",
    "        if transform is None: \n",
    "            self.transform = transforms.ToTensor()\n",
    "        else: \n",
    "            self.transform=transform\n",
    "            \n",
    "        filenames = glob.glob(osp.join(PATH, '*' + EXTENSION))\n",
    "        faces_dic = {}\n",
    "\n",
    "        #################################\n",
    "        # Order the picture per label \n",
    "        #################################\n",
    "\n",
    "        for fn in filenames:\n",
    "            # Extract name of the person from the name of the file\n",
    "            filename = fn.split(PATH)[1]\n",
    "            label = filename.translate(str.maketrans('', '', digits)).split(EXTENSION)[0][1:]\n",
    "\n",
    "            formated_image = self.transform(Image.open(fn).convert(\"RGB\"))\n",
    "\n",
    "            try: \n",
    "                faces_dic[label].append(formated_image)\n",
    "            except KeyError: \n",
    "                faces_dic[label] = [formated_image]\n",
    "                    \n",
    "        all_labels = list(faces_dic.keys())\n",
    "        nb_labels = len(all_labels)\n",
    "        \n",
    "        #############################################\n",
    "        # Build triplet supporting the dataset \n",
    "        #############################################\n",
    "        self.train_data = []\n",
    "        self.train_labels = []\n",
    "        \n",
    "        for label, pictures_list in faces_dic.items():\n",
    "            pictures_indexes_pos = list(range(len(pictures_list)))\n",
    "            shuffle(pictures_indexes_pos)\n",
    "            labels_indexes_neg = [x for x in range(0, nb_labels) if x != all_labels.index(label)]\n",
    "\n",
    "            for i, picture_ref in enumerate(pictures_list):\n",
    "                picture_positive = pictures_list[pictures_indexes_pos.pop()]\n",
    "                # Pick a random different person \n",
    "                label_neg = all_labels[random.choice(labels_indexes_neg)]\n",
    "                picture_negative = random.choice(faces_dic[label_neg]) \n",
    "                self.train_data.append([picture_ref, picture_positive, picture_negative]) # torch.stack is not applied because we want a list of tensors \n",
    "                self.train_labels.append([1,0])\n",
    "                \n",
    "        #self.train_data = torch.stack(self.train_data)\n",
    "        self.train_labels = torch.tensor(self.train_labels)\n",
    "    \n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index, visualization=False):\n",
    "        \"\"\" ---------------------------------------------------------------------------------------------\n",
    "            An item is made up of 3 images (P, P, N) and 2 target (1, 0) specifying that the 2 first \n",
    "            images are the same and the first and the third are different. The images are represented  \n",
    "            through TENSORS. \n",
    "            \n",
    "            If visualize = True: the image is printed \n",
    "            BUG: if visualization = True: RunTimeError due to the returned content (??)\n",
    "        ----------------------------------------------------------------------------------------------- \"\"\" \n",
    "        return self.train_data[index], self.train_labels[index]\n",
    "\n",
    "      \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return len(self.train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "#         TEST         #\n",
    "########################\n",
    "\n",
    "#ds = Face_DS()\n",
    "#ds.__getitem__(1, visualization=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION OF THE NEURAL NETWORK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "   def __init__(self):\n",
    "      super().__init__()\n",
    "      \n",
    "      self.conv1 = nn.Conv2d(3, 64, 7)\n",
    "      self.pool1 = nn.MaxPool2d(2)\n",
    "      self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "      self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "      self.linear1 = nn.Linear(2304, 512)\n",
    "      \n",
    "      self.linear2 = nn.Linear(512, 2)\n",
    "      \n",
    "   def forward(self, data):\n",
    "      res = []\n",
    "      for i in range(2): # Siamese nets; sharing weights\n",
    "         x = data[i]\n",
    "         x = self.conv1(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.conv3(x)\n",
    "         x = F.relu(x)\n",
    "         \n",
    "         x = x.view(x.shape[0], -1)\n",
    "         x = self.linear1(x)\n",
    "         res.append(F.relu(x))\n",
    "         \n",
    "      res = torch.abs(res[1] - res[0])\n",
    "      res = self.linear2(res)\n",
    "      return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION OF THE TRAINING FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output_positive = model(data[:2])\n",
    "        output_negative = model(data[0:3:2])\n",
    "\n",
    "        target = target.type(torch.LongTensor).to(device)\n",
    "        target_positive = torch.squeeze(target[:,0])\n",
    "        target_negative = torch.squeeze(target[:,1])\n",
    "\n",
    "        loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "        loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "\n",
    "        loss = loss_positive + loss_negative\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 10 == 0: # Print the state of the training each 10 batches (i.e each 10*size_batch considered examples)\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx*BATCH_SIZE, len(train_loader.dataset), 100. * batch_idx*BATCH_SIZE / len(train_loader.dataset),\n",
    "            loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION OF THE TESTING FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "   model.eval()\n",
    "   \n",
    "   with torch.no_grad():\n",
    "      accurate_labels = 0\n",
    "      all_labels = 0\n",
    "      loss = 0\n",
    "      for batch_idx, (data, target) in enumerate(test_loader):\n",
    "         for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "         output_positive = model(data[:2])\n",
    "         output_negative = model(data[0:3:2])\n",
    "            \n",
    "         target = target.type(torch.LongTensor).to(device)\n",
    "         target_positive = torch.squeeze(target[:,0])\n",
    "         target_negative = torch.squeeze(target[:,1])\n",
    "            \n",
    "         loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "         loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "            \n",
    "         loss = loss + loss_positive + loss_negative\n",
    "            \n",
    "         accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "         accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "            \n",
    "         accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "         all_labels = all_labels + len(target_positive) + len(target_negative)\n",
    "      \n",
    "      accuracy = 100. * accurate_labels / all_labels\n",
    "      print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINITION OF THE ONE-SHOT FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(model, device, data):\n",
    "   model.eval()\n",
    "\n",
    "   with torch.no_grad():\n",
    "      for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "      \n",
    "      output = model(data)\n",
    "      return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       FUNCTION main                   #\n",
    "#########################################\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Specifies where the torch.tensor is allocated\n",
    "    trans = transforms.Compose([transforms.CenterCrop(28), transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))]) # If applied, a dimensional error is raised \n",
    "    #transforms.CenterCrop(28), \n",
    "    name_model = \"siamese_face\"\n",
    "    extension_model = \".pt\"\n",
    "\n",
    "    model = Net().to(device)\n",
    "    \n",
    "    if DO_LEARN:\n",
    "   \n",
    "        ##################\n",
    "        #  training mode\n",
    "        ##################\n",
    "        train_loader = torch.utils.data.DataLoader(Face_DS(train=True, transform=trans), batch_size=BATCH_SIZE, shuffle=True)\n",
    "        test_loader = torch.utils.data.DataLoader(Face_DS(train=False, transform=trans), batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        for epoch in range(NUM_EPOCH):\n",
    "            train(model, device, train_loader, epoch, optimizer)\n",
    "            test(model, device, test_loader)\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            torch.save(model, (name_model + '{:03}' + extension_model).format(epoch))\n",
    "            print(\"Model is saved!\")\n",
    "      \n",
    "    else: # prediction\n",
    "        dataset = Face_DS(train=True, transform=trans)\n",
    "        prediction_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True) # batch_size = Nb of pairs you want to test \n",
    "      \n",
    "        load_model_path = os.getcwd() + \"/\" + name_model + extension_model #name_model + \"000\" + extension_model\n",
    "        model = torch.load(load_model_path)\n",
    "        \n",
    "        #####################################################################\n",
    "        # Data: list containing the tensor representations of the 2 images\n",
    "        #####################################################################\n",
    "        data = []\n",
    "        data.extend(next(iter(prediction_loader))[0][:3:2])\n",
    "        #print(\"The data given to the onshot function is: \" + str(data))\n",
    "        same = oneshot(model, device, data)\n",
    "        if same > 0:\n",
    "            print('These two images represent the same person')\n",
    "        else:\n",
    "            print(\"These two images don't represent the same person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These two images represent the same person\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
