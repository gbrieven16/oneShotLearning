{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CODE FROM https://becominghuman.ai/siamese-networks-algorithm-applications-and-pytorch-implementation-4ffa3304c18 \n",
    "Classifying MNIST Images Using A Siamese Network In PyTorch\n",
    "\n",
    "The aim of the network here is differentiating images, i.e. outputting \"True\" if a given pair of images represent the same number and \"False\" otherwise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#          ALL THE IMPORTS              #\n",
    "#########################################\n",
    "\n",
    "import codecs\n",
    "import errno\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets.mnist\n",
    "from torchvision.datasets.mnist import read_image_file, read_label_file\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       ALL THE GENRAL CONSTANTS        #\n",
    "#########################################\n",
    "do_learn = False\n",
    "save_frequency = 2 # Maybe to save the intermed\n",
    "batch_size = 16# => At each iteration: 160 inputs (among 5000) are considered \n",
    "lr = 0.001\n",
    "num_epochs = 10 \n",
    "weight_decay = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       CLASS BALANCED MNISTPAIR        #\n",
    "#########################################\n",
    "\n",
    "class BalancedMNISTPair(torch.utils.data.Dataset):\n",
    "   \"\"\" ---------------------------------------------------------------\n",
    "   Dataset that on each iteration provides two random pairs of\n",
    "   MNIST images. One pair is of the same number (positive sample), one\n",
    "   is of two different numbers (negative sample).\n",
    "   BalancedMNISTPair herits of all the methods and variables of \n",
    "   torch.utils.data.Dataset\n",
    "   ---------------------------------------------------------------\"\"\"\n",
    "   urls = [\n",
    "      'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz',\n",
    "      'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz',\n",
    "      'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz',\n",
    "      'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz',\n",
    "   ]\n",
    "   raw_folder = 'raw'\n",
    "   processed_folder = 'processed'\n",
    "   training_file = 'training.pt'\n",
    "   test_file = 'test.pt'\n",
    "   \n",
    "   def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "      self.root = os.path.expanduser(root)\n",
    "      self.transform = transform\n",
    "      self.target_transform = target_transform\n",
    "      self.train = train # training set or test set\n",
    "      \n",
    "      if download:\n",
    "         self.download()\n",
    "         \n",
    "      if not self._check_exists():\n",
    "         raise RuntimeError('Dataset not found.' + ' You can use download=True to download it')\n",
    "         \n",
    "        \n",
    "         ###########################################\n",
    "         # FOR TRAINING\n",
    "         ###########################################\n",
    "\n",
    "      if self.train:\n",
    "         self.train_data, self.train_labels = torch.load(\n",
    "            os.path.join(self.root, self.processed_folder, self.training_file))\n",
    "\n",
    "         train_labels_class = []\n",
    "         train_data_class = []\n",
    "         for i in range(10):\n",
    "            indices = torch.squeeze((self.train_labels == i).nonzero())\n",
    "            train_labels_class.append(torch.index_select(self.train_labels, 0, indices))\n",
    "            train_data_class.append(torch.index_select(self.train_data, 0, indices))\n",
    "            \n",
    "         ###########################################\n",
    "         # Generate balanced pairs\n",
    "         ###########################################\n",
    "\n",
    "         self.train_data = []\n",
    "         self.train_labels = []\n",
    "         lengths = [x.shape[0] for x in train_labels_class]\n",
    "         for i in range(10):\n",
    "            for j in range(500): # create 500 pairs\n",
    "               rnd_cls = random.randint(0,8) # choose random class that is not the same class\n",
    "               if rnd_cls >= i:\n",
    "                  rnd_cls = rnd_cls + 1\n",
    "\n",
    "               rnd_dist = random.randint(0, 100)\n",
    "                  \n",
    "               self.train_data.append(torch.stack([train_data_class[i][j], train_data_class[i][j+rnd_dist], train_data_class[rnd_cls][j]]))\n",
    "               self.train_labels.append([1,0])\n",
    "            \n",
    "         self.train_data = torch.stack(self.train_data)\n",
    "         self.train_labels = torch.tensor(self.train_labels)\n",
    "           \n",
    "        \n",
    "         ###########################################\n",
    "         # FOR TESTING \n",
    "         ###########################################\n",
    "\n",
    "      else:\n",
    "         self.test_data, self.test_labels = torch.load(\n",
    "            os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "         \n",
    "         test_labels_class = []\n",
    "         test_data_class = []\n",
    "         for i in range(10):\n",
    "            indices = torch.squeeze((self.test_labels == i).nonzero())\n",
    "            test_labels_class.append(torch.index_select(self.test_labels, 0, indices))\n",
    "            test_data_class.append(torch.index_select(self.test_data, 0, indices))\n",
    "            \n",
    "            \n",
    "         ###########################################\n",
    "         # Generate balanced pairs\n",
    "         ###########################################\n",
    "         self.test_data = []\n",
    "         self.test_labels = []\n",
    "         lengths = [x.shape[0] for x in test_labels_class]\n",
    "         for i in range(10):\n",
    "            for j in range(500): # create 500 pairs\n",
    "               rnd_cls = random.randint(0,8) # choose random class that is not the same class\n",
    "               if rnd_cls >= i:\n",
    "                  rnd_cls = rnd_cls + 1\n",
    "\n",
    "               rnd_dist = random.randint(0, 100)\n",
    "                  \n",
    "               self.test_data.append(torch.stack([test_data_class[i][j], test_data_class[i][j+rnd_dist], test_data_class[rnd_cls][j]]))\n",
    "               self.test_labels.append([1,0])\n",
    "\n",
    "         self.test_data = torch.stack(self.test_data)\n",
    "         self.test_labels = torch.tensor(self.test_labels)\n",
    "\n",
    "         \n",
    "   def __getitem__(self, index):\n",
    "      if self.train:\n",
    "        imgs, target = self.train_data[index], self.train_labels[index]\n",
    "      else:\n",
    "        imgs, target = self.test_data[index], self.test_labels[index]\n",
    "        \n",
    "      img_ar = []\n",
    "      for i in range(len(imgs)):\n",
    "         img = Image.fromarray(imgs[i].numpy(), mode='L')\n",
    "         if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            img_ar.append(img)\n",
    "         \n",
    "      if self.target_transform is not None:\n",
    "         target = self.target_transform(target)\n",
    "         \n",
    "      return img_ar, target\n",
    "   \n",
    "   def __len__(self):\n",
    "      if self.train:\n",
    "         return len(self.train_data)\n",
    "      else:\n",
    "         return len(self.test_data)\n",
    "      \n",
    "   def _check_exists(self):\n",
    "      return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "         os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "   \n",
    "   def download(self):\n",
    "      \"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"\n",
    "      from six.moves import urllib\n",
    "      import gzip\n",
    "\n",
    "      if self._check_exists():\n",
    "         return\n",
    "\n",
    "      # download files\n",
    "      try:\n",
    "         os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "         os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "      except OSError as e:\n",
    "         if e.errno == errno.EEXIST:\n",
    "            pass\n",
    "         else:\n",
    "            raise\n",
    "\n",
    "      for url in self.urls:\n",
    "         print('Downloading ' + url)\n",
    "         data = urllib.request.urlopen(url)\n",
    "         filename = url.rpartition('/')[2]\n",
    "         file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "         with open(file_path, 'wb') as f:\n",
    "            f.write(data.read())\n",
    "         with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "               gzip.GzipFile(file_path) as zip_f:\n",
    "            out_f.write(zip_f.read())\n",
    "         os.unlink(file_path)\n",
    "\n",
    "      # process and save as torch files\n",
    "      print('Processing in download function...')\n",
    "\n",
    "      training_set = (\n",
    "         read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "         read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "      )\n",
    "      test_set = (\n",
    "         read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "         read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "      )\n",
    "      with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "         torch.save(training_set, f)\n",
    "      with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "         torch.save(test_set, f)\n",
    "\n",
    "      print('Download of the data is Done!')\n",
    "\n",
    "   def __repr__(self):\n",
    "      fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n",
    "      fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n",
    "      tmp = 'train' if self.train is True else 'test'\n",
    "      fmt_str += '    Split: {}\\n'.format(tmp)\n",
    "      fmt_str += '    Root Location: {}\\n'.format(self.root)\n",
    "      tmp = '    Transforms (if any): '\n",
    "      fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "      tmp = '    Target Transforms (if any): '\n",
    "      fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n",
    "      return fmt_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# TEST PART JUST TO VISUALIZE THE DATASET\n",
    "###############################################\n",
    "#trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "#ds = BalancedMNISTPair('../data', train=False, download=True, transform=trans)\n",
    "#ds.__getitem__(9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       CLASS Net                       #\n",
    "#########################################\n",
    "class Net(nn.Module):\n",
    "   def __init__(self):\n",
    "      super().__init__()\n",
    "      \n",
    "      self.conv1 = nn.Conv2d(1, 64, 7)\n",
    "      self.pool1 = nn.MaxPool2d(2)\n",
    "      self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "      self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "      self.linear1 = nn.Linear(2304, 512)\n",
    "      \n",
    "      self.linear2 = nn.Linear(512, 2) # 512 output features \n",
    "      \n",
    "   def forward(self, data):\n",
    "      res = []\n",
    "      for i in range(2): # Siamese nets; sharing weights\n",
    "         x = data[i]\n",
    "         x = self.conv1(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = F.relu(x)\n",
    "         x = self.conv3(x)\n",
    "         x = F.relu(x)\n",
    "         \n",
    "         x = x.view(x.shape[0], -1)\n",
    "         x = self.linear1(x)\n",
    "         res.append(F.relu(x))\n",
    "         \n",
    "      res = torch.abs(res[1] - res[0])\n",
    "      res = self.linear2(res)\n",
    "      return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       FUNCTION train                  #\n",
    "#########################################\n",
    "\n",
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "   model.train()\n",
    "   \n",
    "   for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      #print(\"IN TRAIN: the data is \" + str(data))\n",
    "      for i in range(len(data)):\n",
    "         #print(\"IN TRAIN: 1 data is \" + str(data[i]))\n",
    "         data[i] = data[i].to(device)\n",
    "         #print(\"IN TRAIN: 1 data after application to device is \" + str(data[i]))\n",
    "\n",
    "         \n",
    "      optimizer.zero_grad()\n",
    "      output_positive = model(data[:2]) # Take the 2 first images corresponding to the positive couple\n",
    "      output_negative = model(data[0:3:2]) # Take the first and the third images corresponding to the negative couple\n",
    "      \n",
    "      target = target.type(torch.LongTensor).to(device)\n",
    "      print(\"IN TRAIN: the type of target is \" + str(type(target)))\n",
    "      print(\"IN TRAIN: the target is \" + str(target))\n",
    "\n",
    "      target_positive = torch.squeeze(target[:,0]) # Removes 1 dimension \n",
    "      target_negative = torch.squeeze(target[:,1])\n",
    "      \n",
    "      loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "      loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "      \n",
    "      loss = loss_positive + loss_negative\n",
    "      loss.backward() # Minimization \n",
    "      \n",
    "      optimizer.step()\n",
    "      if batch_idx % 10 == 0:\n",
    "         print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx*batch_size, len(train_loader.dataset), 100. * batch_idx*batch_size / len(train_loader.dataset),\n",
    "            loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       FUNCTION test                   #\n",
    "#########################################\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "   model.eval()\n",
    "   \n",
    "   with torch.no_grad():\n",
    "      accurate_labels = 0\n",
    "      all_labels = 0\n",
    "      loss = 0\n",
    "      for batch_idx, (data, target) in enumerate(test_loader):\n",
    "         for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "         output_positive = model(data[:2])\n",
    "         output_negative = model(data[0:3:2])\n",
    "            \n",
    "         target = target.type(torch.LongTensor).to(device)\n",
    "         target_positive = torch.squeeze(target[:,0])\n",
    "         target_negative = torch.squeeze(target[:,1])\n",
    "            \n",
    "         loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "         loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "            \n",
    "         loss = loss + loss_positive + loss_negative\n",
    "            \n",
    "         accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "         accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "            \n",
    "         accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "         all_labels = all_labels + len(target_positive) + len(target_negative)\n",
    "      \n",
    "      accuracy = 100. * accurate_labels / all_labels\n",
    "      print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       FUNCTION oneshot                #\n",
    "#########################################\n",
    "\n",
    "def oneshot(model, device, data):\n",
    "   model.eval()\n",
    "\n",
    "   with torch.no_grad():\n",
    "      for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "      \n",
    "      output = model(data)\n",
    "      print(\"IN ONE SHOT FCT, the output is \" + str(output))\n",
    "      return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "#       FUNCTION main                   #\n",
    "#########################################\n",
    "\n",
    "def main():\n",
    "   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "   trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "   name_model = \"siamese_\"\n",
    "   extension_model = \".pt\"\n",
    "   \n",
    "   model = Net().to(device)\n",
    "   \n",
    "   if do_learn: # training mode\n",
    "      train_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=True, download=True, transform=trans), batch_size=batch_size, shuffle=True)\n",
    "      test_loader = torch.utils.data.DataLoader(BalancedMNISTPair('../data', train=False, download=True, transform=trans), batch_size=batch_size, shuffle=False)\n",
    "      \n",
    "      optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "      for epoch in range(num_epochs):\n",
    "         train(model, device, train_loader, epoch, optimizer)\n",
    "         test(model, device, test_loader)\n",
    "         if epoch & save_frequency == 0:\n",
    "            torch.save(model, (name_model + '{:03}' + extension_model).format(epoch))\n",
    "            print(\"Model is saved!\")\n",
    "      \n",
    "   else: # prediction\n",
    "      dataset = BalancedMNISTPair('../data', train=False, download=True, transform=trans)\n",
    "      #print(dataset.__repr__)\n",
    "      prediction_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "      \n",
    "      load_model_path = os.getcwd() + \"/\" + name_model + \"000\" + extension_model\n",
    "      #model.load_state_dict(torch.load(load_model_path))\n",
    "      model = torch.load(load_model_path)\n",
    "\n",
    "      #####################################################################\n",
    "      # Data: list containing the tensor representations of the 2 images\n",
    "      #####################################################################\n",
    "      data = []\n",
    "      data.extend(next(iter(prediction_loader))[0][:3:2])\n",
    "      same = oneshot(model, device, data)\n",
    "      if same > 0:\n",
    "         print('These two images are of the same number')\n",
    "      else:\n",
    "         print('These two images are not of the same number')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN ONE SHOT FCT, the output is tensor([[-1.0685,  1.5143]])\n",
      "These two images are of the same number\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
